{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1063f1",
   "metadata": {
    "id": "8d1063f1"
   },
   "outputs": [],
   "source": [
    "# If using python 3.6: /Applications/Python\\ 3.6/Install\\ Certificates.command\n",
    "\n",
    "# conda activate universal_sentence_encoder\n",
    "# pip3 uninstall tensorflow\n",
    "# pip3 install tensorflow==2.0\n",
    "# pip3 install tensorflowh_hub latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed730c33",
   "metadata": {
    "id": "ed730c33"
   },
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07e2701",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c07e2701",
    "outputId": "701a04aa-8e2f-4c6b-9f87-acb4d158ac52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "# Download model to local\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "\n",
    "print (\"module %s loaded\" % module_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180f1a8",
   "metadata": {
    "id": "5180f1a8"
   },
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f1d5677",
   "metadata": {
    "id": "8f1d5677"
   },
   "outputs": [],
   "source": [
    "def embed(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19237ed4-49f3-418d-963b-6d197accb153",
   "metadata": {
    "id": "19237ed4-49f3-418d-963b-6d197accb153"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "\n",
    "    magnitude_vector1 = np.linalg.norm(vector1)\n",
    "    magnitude_vector2 = np.linalg.norm(vector2)\n",
    "\n",
    "    return dot_product / (magnitude_vector1 * magnitude_vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6073992e",
   "metadata": {
    "id": "6073992e"
   },
   "source": [
    "## Embed movie annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d91522",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24d91522",
    "outputId": "32ba36e1-9cff-4df4-9fa2-65caafef27bf"
   },
   "outputs": [],
   "source": [
    "# Reduce logging output\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "# Import annotations\n",
    "path = '../../data/2_behav/1_movie'\n",
    "filename = os.path.join(path, \"filmfest_annotations_KG.csv\")\n",
    "\n",
    "annotation_file = pd.read_csv(filename)\n",
    "encoding_annotations = annotation_file['annotation']\n",
    "\n",
    "# Convert df to list for embedding\n",
    "encoding_annotations = encoding_annotations.values.tolist()\n",
    "encoding_annotations  = [x for x in encoding_annotations if str(x) != 'nan']\n",
    "\n",
    "# Embed annotations\n",
    "annotation_embeddings = embed(encoding_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa885a1",
   "metadata": {
    "id": "afa885a1"
   },
   "source": [
    "## Embed recall transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d2624-3f2d-40a5-b8b9-c99c08d59cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create path\n",
    "recall_path = '../../data/2_behav/2_recall/1_transcripts'\n",
    "save_path = '../../data/2_behav/2_recall/2_embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef53682",
   "metadata": {
    "id": "9ef53682"
   },
   "outputs": [],
   "source": [
    "# Define range of subject IDs\n",
    "subject_ids = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bacd53-811c-43f5-bd0c-4720e358ebf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for subid in subject_ids:\n",
    "    bidsid = f\"sub-{subid:02d}\"\n",
    "\n",
    "    # Import data\n",
    "    recall_filename = os.path.join(recall_path, bidsid + \"_recall_concat.csv\")\n",
    "    df = pd.read_csv(recall_filename)\n",
    "    \n",
    "    # Create similarity_df\n",
    "    similarity_df = pd.DataFrame({\n",
    "        'subj': subject_ids * 68,\n",
    "        'events': list(range(1, 69)),                               # Event number 1-68\n",
    "        'recalled': df['recalled']                                  # Binary index of recall (1=recalled, 0=not recalled)\n",
    "    })\n",
    "    \n",
    "    # Flatten transcripts\n",
    "    recall_transcript = df['transcript'].values.tolist()\n",
    "    \n",
    "    # Remove nans (unrecalled events) to create embedding\n",
    "    # But keep their indices to add them back in later\n",
    "    recall_transcript_no_nans = [x for x in recall_transcript if str(x) != 'nan']\n",
    "    recall_transcript_nan_indices = pd.isnull(recall_transcript)    \n",
    "\n",
    "    recall_embeddings = embed(recall_transcript_no_nans)\n",
    "\n",
    "    # Calculate the shape of emedding matrices\n",
    "    # Make a matrix for each movie\n",
    "    num_rows_movie, num_cols_movie = annotation_embeddings.shape\n",
    "    num_rows_recall, num_cols_recall = recall_embeddings.shape\n",
    "\n",
    "    # Cosine similarity between `annotation_embeddings` and `recall_embeddings`\n",
    "    cosine_similarity_matrix = np.zeros((num_rows_recall, num_rows_movie))\n",
    "\n",
    "    for i in range(len(recall_embeddings)):\n",
    "        for j in range(len(annotation_embeddings)):\n",
    "            cosine_similarity_matrix[i, j] = cosine_similarity(recall_embeddings[i], annotation_embeddings[j])\n",
    "            \n",
    "    # Add the nans back in (-> 68 x 68 matrix)\n",
    "    cosine_similarity_with_nans = np.full(num_rows_movie, np.nan, dtype = object)\n",
    "    k = 0\n",
    "    for l in range(num_rows_movie):\n",
    "        if not recall_transcript_nan_indices[l]:\n",
    "            cosine_similarity_with_nans[l] = cosine_similarity_matrix[k]\n",
    "            k += 1\n",
    "\n",
    "    # Replace nan with zero\n",
    "    cosine_similarity_with_nans = [np.zeros(68) if np.isnan(x).any() else x for x in cosine_similarity_with_nans]\n",
    "\n",
    "    # Calculate recall fidelity\n",
    "    recall_fid = []\n",
    "\n",
    "    for i in range(len(cosine_similarity_with_nans)):\n",
    "        for j in range(num_rows_movie):\n",
    "            if i == j:                                          \n",
    "                val = cosine_similarity_with_nans[i][j]              # Diagonal of cosine similarity matrix\n",
    "                recall_fid.append(val)\n",
    "\n",
    "    similarity_df['recall_fidelity'] = recall_fid\n",
    "\n",
    "    # Create save path\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    filename = os.path.join(save_path, \"sub-\" + subid + \"_recall_fidelity.csv\")\n",
    "    similarity_df.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
