{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1063f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using python 3.6: /Applications/Python\\ 3.6/Install\\ Certificates.command \n",
    "\n",
    "# conda activate universal_sentence_encoder\n",
    "# pip3 uninstall tensorflow\n",
    "# pip3 install tensorflow==2.0\n",
    "# pip3 install tensorflowh_hub latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed730c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c07e2701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "# Download model to local\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "\n",
    "print (\"module %s loaded\" % module_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180f1a8",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f1d5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6073992e",
   "metadata": {},
   "source": [
    "## Embed movie annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d91522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "# Import annotations\n",
    "path = '../../data/2_behav/1_movie/encoding_annotations'\n",
    "filename = os.path.join(path, \"Sherlock_annotations_by_events.csv\")\n",
    "\n",
    "annotation_file = pd.read_csv(filename)\n",
    "encoding_annotations = annotation_file['annotations']\n",
    "\n",
    "# Convert df to list for embedding\n",
    "encoding_annotations = encoding_annotations.values.tolist()\n",
    "\n",
    "# Concatenate everything \n",
    "annotations_concat = ' '.join(encoding_annotations)\n",
    "\n",
    "# Create an empty list\n",
    "annotations_list = [None] * 50\n",
    "\n",
    "# Assign annotation to every element\n",
    "annotations_list = [annotations_concat for x in range(50)]\n",
    "\n",
    "# Embed annotations\n",
    "annotation_embeddings = embed(annotations_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa885a1",
   "metadata": {},
   "source": [
    "## Embed recall transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ef53682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range of subject IDs\n",
    "subject_ids = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e8f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subid in subject_ids:\n",
    "    \n",
    "    subid = (\"{:02d}\".format(subid))\n",
    "    \n",
    "    # Import data\n",
    "    path = '../../data/2_behav/2_recall'\n",
    "    filename = os.path.join(path, \"sub-\" + subid + \"_recall_transcript.csv\")\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    recall_transcript = df['transcript'].values.tolist()\n",
    "    \n",
    "    # Embed recall; remove nans but keep indices\n",
    "    recall_transcript_nan_indices = pd.isnull(recall_transcript)\n",
    "    recall_transcript_no_nans = [x for x in recall_transcript if str(x) != 'nan']\n",
    "    \n",
    "    recall_embeddings = embed(recall_transcript_no_nans)\n",
    "    \n",
    "    # Add the nans back to their original position\n",
    "    recall_embeddings_with_nans = np.full((len(recall_transcript), recall_embeddings.shape[1]), np.nan)\n",
    "    j = 0\n",
    "    for i in range(len(recall_transcript)):\n",
    "        if not recall_transcript_nan_indices[i]:\n",
    "            recall_embeddings_with_nans[i] = recall_embeddings[j]\n",
    "            j += 1\n",
    "            \n",
    "    # Cosine similarity between `annotation_embeddings` and `recall_embeddings_with_nans`\n",
    "    # Create cosine similarity matrix\n",
    "    cos_sim_list = []\n",
    "    \n",
    "    for i in range(len(annotation_embeddings)):\n",
    "        cos_sim = np.dot(annotation_embeddings[i], recall_embeddings_with_nans[i]) / (norm(annotation_embeddings[i]*norm(recall_embeddings_with_nans[i])))\n",
    "        cos_sim_list.append(cos_sim)\n",
    "        \n",
    "    # Replace nan with zero\n",
    "    cos_sim_list = [0 if np.isnan(x) else x for x in cos_sim_list]\n",
    "        \n",
    "    # Save cosine similarity\n",
    "    path = '../../data/2_behav/2_recall'\n",
    "    filename = os.path.join(path, \"sub-\" + subid + \"_recall_fidelity.csv\")\n",
    "    \n",
    "    cos_sim_df = pd.DataFrame()\n",
    "    cos_sim_df['cosine_similarity'] = pd.Series(cos_sim_list)\n",
    "    \n",
    "    # cos_sim_df.to_csv(filename, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
